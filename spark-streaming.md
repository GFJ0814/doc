spark-streaming

1.什么是实时任务，举例子

2.spark-streaming怎么处理实时任务   DStream

 实时任务处理的三个过程：获取数据、处理数据、输出数据

DStream是什么，怎么来的，批次时间如何设置

工作原理，spark-streaming和Spark的关系



3、获取数据

​	数据源：kafka、flume等，数据高可用，备份

​        数据源分类，怎么分的，有何区别        

​	接收器

4、处理数据：算子

​	转化操作：

​		有状态转化、无状态转化

​		基于窗口的操作

​	

5、action操作：输出



6、累加器和广播变量



7、检查点：

​	检查点分类，如何设计、如何使用检查点，检查点的特殊用法

8、发布与调优



9、实时计算在贝壳

​	看懂sparkUI图

- 一个batch可以分成两个job，batch、job之间的关系、stage等

10.spark使用问题

- 数据倾斜以及解决方案
- spark代码怎么能提高可读性和可编程性（函数式编程）
- 广播变量的产生背景

11.优点以及缺陷

12.流计算 strom、Flink、spark-streaming特点对比

​	https://www.jianshu.com/p/16323566f3c6

13、思考：如果sparkstreaming任务执行时候，一个excutor挂了该怎么办，任务执行节点

​		   如果sparkstreaming任务执行的时候，一个reciver节点挂了该怎么办，怎样高可用

14.高容错性质怎么保证

15.调优

​	思想：提高集群资源利用率，减少单批次任务处理耗时、合理设置批次大小，保证处理速度能够跟上数据接收速度

​	（1）性能调优

- 提升数据接收并发度
- 提高数据处理并发度
- 数据序列化 ：由于streaming数据默认存储的级别是优先存储内存，其次序列化到磁盘，因此，序列化方式显得很重要，减少序列化的时间性能消耗
- 任务启动开销
- 设置合适的批次间隔，通过查看任务的延时情况，找到和任务延时情况基本上一致的时间间隔
- 内存调优：目的是尽量将数据保存到内存，减少磁盘IO，保存到内存的数据如何减少GC次数
- 

16 容错语义实现

​	根据可靠度区分：至多一次，至少一次，精确一次

​        处理步骤容错：

- 数据接收容错方式
  - 不同数据源有所不同
- 数据处理容错：RDD本身的血缘关系图容错
- 数据输出容错：输出到介质的幂等性以及输出数据事务操作保证
- 

TODO:

​	1.去掉架构图

​	2.算子重点讲窗口计算，差异性

​	3.流式系统可靠度语义去掉

​	4.检查点去掉集中的汉字

​	5.sql、dataSet、DataFrame

问题：

​	（1）阐述过程

​	（2）UI图

​	（3）窗口计算

​	（4）Dataframe和rdd







​       



